{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gu7B9aDPTPPaaqB4Kq5fkObe4iuomEW6",
      "authorship_tag": "ABX9TyPDBxspRIJhbX7u0NfoiSaY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KellySantosG/Progrmaci-n-tareas-/blob/main/Proyecto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qvTGRD24HJd",
        "outputId": "030ffcde-b8fe-4d4a-e9d5-bbaf51f461b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-200404879ad2>:36: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Logística: Precisión = 0.94\n",
            "KNN: Precisión = 0.94\n",
            "SVM: Precisión = 0.21\n",
            "Árbol de Decisión: Precisión = 0.93\n"
          ]
        }
      ],
      "source": [
        "# Kelly Santos García\n",
        "\n",
        "# Lo que importamos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Empieza el codigo\n",
        "# Clase base para los clasificadores\n",
        "class Clasificadores:\n",
        "    def __init__(self):\n",
        "        self.entrenado = False\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        \"\"\"\n",
        "        Método abstracto para entrenar el clasificador.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"El método 'entrenar' debe ser implementado por las subclases.\")\n",
        "\n",
        "    def predecir(self, X):\n",
        "        \"\"\"\n",
        "        Método abstracto para realizar predicciones.\n",
        "        \"\"\"\n",
        "        if not self.entrenado:\n",
        "            raise Exception(\"El clasificador debe estar entrenado antes de predecir.\")\n",
        "        raise NotImplementedError(\"El método 'predecir' debe ser implementado por las subclases.\")\n",
        "\n",
        "# Implementación de la Regresión Logística\n",
        "class RegresionLogistica(Clasificadores):\n",
        "    def __init__(self, tasa_aprendizaje=0.01, iteraciones=1000):\n",
        "        super().__init__()\n",
        "        self.tasa_aprendizaje = tasa_aprendizaje\n",
        "        self.iteraciones = iteraciones\n",
        "        self.pesos = None\n",
        "\n",
        "    def _sigmoide(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.pesos = np.zeros(n)\n",
        "        for _ in range(self.iteraciones):\n",
        "            z = np.dot(X, self.pesos)\n",
        "            predicciones = self._sigmoide(z)\n",
        "            gradiente = np.dot(X.T, (predicciones - y)) / m\n",
        "            self.pesos -= self.tasa_aprendizaje * gradiente\n",
        "        self.entrenado = True\n",
        "\n",
        "    def predecir(self, X):\n",
        "        z = np.dot(X, self.pesos)\n",
        "        return (self._sigmoide(z) >= 0.5).astype(int)\n",
        "\n",
        "# Implementación de k-Nearest Neighbors\n",
        "class KNN(Clasificadores):\n",
        "    def __init__(self, k=3):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.X_entrenamiento = None\n",
        "        self.y_entrenamiento = None\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        self.X_entrenamiento = X\n",
        "        self.y_entrenamiento = y\n",
        "        self.entrenado = True\n",
        "\n",
        "    def predecir(self, X):\n",
        "        predicciones = []\n",
        "        for x in X:\n",
        "            distancias = np.linalg.norm(self.X_entrenamiento - x, axis=1)\n",
        "            indices = np.argsort(distancias)[:self.k]\n",
        "            etiquetas = self.y_entrenamiento[indices]\n",
        "            predicciones.append(np.argmax(np.bincount(etiquetas)))\n",
        "        return np.array(predicciones)\n",
        "\n",
        "# Implementación de SVM\n",
        "class SVM(Clasificadores):\n",
        "    def __init__(self, tasa_aprendizaje=0.01, iteraciones=1000, C=1.0):\n",
        "        super().__init__()\n",
        "        self.tasa_aprendizaje = tasa_aprendizaje\n",
        "        self.iteraciones = iteraciones\n",
        "        self.C = C\n",
        "        self.pesos = None\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.pesos = np.zeros(n)\n",
        "        for _ in range(self.iteraciones):\n",
        "            for i in range(m):\n",
        "                if y[i] * np.dot(X[i], self.pesos) < 1:\n",
        "                    self.pesos += self.tasa_aprendizaje * (y[i] * X[i] + (-2 * (1 / self.C) * self.pesos))\n",
        "                else:\n",
        "                    self.pesos += self.tasa_aprendizaje * (-2 * (1 / self.C) * self.pesos)\n",
        "        self.entrenado = True\n",
        "\n",
        "    def predecir(self, X):\n",
        "        return np.sign(np.dot(X, self.pesos))\n",
        "\n",
        "# Implementación de Árbol de Decisión\n",
        "class NodoArbol:\n",
        "    def __init__(self, caracteristica=None, umbral=None, izquierda=None, derecha=None, valor=None):\n",
        "        self.caracteristica = caracteristica\n",
        "        self.umbral = umbral\n",
        "        self.izquierda = izquierda\n",
        "        self.derecha = derecha\n",
        "        self.valor = valor\n",
        "\n",
        "class ArbolDecision(Clasificadores):\n",
        "    def __init__(self, profundidad_maxima=5):\n",
        "        super().__init__()\n",
        "        self.profundidad_maxima = profundidad_maxima\n",
        "        self.raiz = None\n",
        "\n",
        "    def _calcular_gini(self, y):\n",
        "        proporciones = np.bincount(y) / len(y)\n",
        "        return 1 - np.sum(proporciones**2)\n",
        "\n",
        "    def _dividir(self, X, y, caracteristica, umbral):\n",
        "        izquierda = np.where(X[:, caracteristica] <= umbral)\n",
        "        derecha = np.where(X[:, caracteristica] > umbral)\n",
        "        return (X[izquierda], y[izquierda]), (X[derecha], y[derecha])\n",
        "\n",
        "    def _crear_arbol(self, X, y, profundidad):\n",
        "        if profundidad == self.profundidad_maxima or len(set(y)) == 1:\n",
        "            valor = np.argmax(np.bincount(y))\n",
        "            return NodoArbol(valor=valor)\n",
        "\n",
        "        caracteristica, umbral = None, None\n",
        "        mejor_gini = float(\"inf\")\n",
        "        for i in range(X.shape[1]):\n",
        "            umbrales = np.unique(X[:, i])\n",
        "            for u in umbrales:\n",
        "                (X_izq, y_izq), (X_der, y_der) = self._dividir(X, y, i, u)\n",
        "                gini = (len(y_izq) * self._calcular_gini(y_izq) + len(y_der) * self._calcular_gini(y_der)) / len(y)\n",
        "                if gini < mejor_gini:\n",
        "                    mejor_gini, caracteristica, umbral = gini, i, u\n",
        "\n",
        "        (X_izq, y_izq), (X_der, y_der) = self._dividir(X, y, caracteristica, umbral)\n",
        "        izquierda = self._crear_arbol(X_izq, y_izq, profundidad + 1)\n",
        "        derecha = self._crear_arbol(X_der, y_der, profundidad + 1)\n",
        "        return NodoArbol(caracteristica=caracteristica, umbral=umbral, izquierda=izquierda, derecha=derecha)\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        self.raiz = self._crear_arbol(X, y, 0)\n",
        "        self.entrenado = True\n",
        "\n",
        "    def _predecir_unico(self, nodo, x):\n",
        "        if nodo.valor is not None:\n",
        "            return nodo.valor\n",
        "        if x[nodo.caracteristica] <= nodo.umbral:\n",
        "            return self._predecir_unico(nodo.izquierda, x)\n",
        "        return self._predecir_unico(nodo.derecha, x)\n",
        "\n",
        "    def predecir(self, X):\n",
        "        return np.array([self._predecir_unico(self.raiz, x) for x in X])\n",
        "\n",
        "# Implementación de Random Forest\n",
        "class RandomForest(Clasificadores):\n",
        "    def __init__(self, n_estimadores=10, profundidad_maxima=5):\n",
        "        super().__init__()\n",
        "        self.n_estimadores = n_estimadores\n",
        "        self.profundidad_maxima = profundidad_maxima\n",
        "        self.bosque = []\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        m = len(y)\n",
        "        for _ in range(self.n_estimadores):\n",
        "            indices = np.random.choice(m, m, replace=True)\n",
        "            X_muestra = X[indices]\n",
        "            y_muestra = y[indices]\n",
        "            arbol = ArbolDecision(profundidad_maxima=self.profundidad_maxima)\n",
        "            arbol.entrenar(X_muestra, y_muestra)\n",
        "            self.bosque.append(arbol)\n",
        "        self.entrenado = True\n",
        "\n",
        "    def predecir(self, X):\n",
        "        predicciones = np.array([arbol.predecir(X) for arbol in self.bosque])\n",
        "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predicciones)\n",
        "\n",
        "# Código principal para prueba de clasificadores (bloque __main__)\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Cargar los datos\n",
        "        data = pd.read_csv('/content/drive/MyDrive/cancer.csv')\n",
        "\n",
        "        # Separar datos para entrenamiento y prueba\n",
        "        X = data.iloc[:, 2:].values  # Características\n",
        "        y = (data['diagnosis'] == 'M').astype(int).values  # Etiquetas binarias (M = 1, B = 0)\n",
        "        X_entrenamiento, X_prueba = X[:400], X[400:]\n",
        "        y_entrenamiento, y_prueba = y[:400], y[400:]\n",
        "\n",
        "        # Crear y entrenar clasificadores\n",
        "        clasificadores = {\n",
        "            \"Regresión Logística\": RegresionLogistica(),\n",
        "            \"KNN\": KNN(),\n",
        "            \"SVM\": SVM(),\n",
        "            \"Árbol de Decisión\": ArbolDecision(),\n",
        "            \"Random Forest\": RandomForest()\n",
        "        }\n",
        "\n",
        "        for nombre, clasificador in clasificadores.items():\n",
        "            clasificador.entrenar(X_entrenamiento, y_entrenamiento)\n",
        "            y_pred = clasificador.predecir(X_prueba)\n",
        "            precision = np.mean(y_pred == y_prueba)\n",
        "            print(f\"{nombre}: Precisión = {precision:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en la ejecución: {e}\")"
      ]
    }
  ]
}